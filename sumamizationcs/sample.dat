{
    "values": [
      {
        "recordId": "0",
        "data":
           {
            "text": "At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic,human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI CognitiveServices, I have been working with a team of amazing scientists and engineers to turn this quest into areality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes ofhuman cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At theintersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a jointrepresentation to create more powerful AI that can speak, hear, see, and understand humans better.We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning,spanning modalities and languages. The goal is to have pretrained models that can jointly learnrepresentations to support a broad range of downstream AI tasks, much in the way humans do today.Over the past five years, we have achieved human performance on benchmarks in conversational speechrecognition, machine translation, conversational question answering, machine reading comprehension,and image captioning. These five breakthroughs provided us with strong signals toward our more ambitiousaspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning thatis closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundationalcomponent of this aspiration, if grounded with external knowledge sources in the downstream AI tasks."
           }
      }
     
    ]
}